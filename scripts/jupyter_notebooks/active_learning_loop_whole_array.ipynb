{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f723e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "# os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "# os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "#os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=1024'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import src.fitting as fitting\n",
    "import src.multielec_utils as mutils\n",
    "import statsmodels.api as sm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.io import savemat, loadmat\n",
    "import optax\n",
    "from copy import copy\n",
    "import multiprocessing as mp\n",
    "import collections\n",
    "import visionloader as vl\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0718fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_probs(x, w):\n",
    "    # w : site weights, n x d\n",
    "    # x : current levels, c x d\n",
    "    site_activations = jnp.dot(w, jnp.transpose(x)) # dimensions: n x c\n",
    "    p_sites = jax.nn.sigmoid(site_activations) # dimensions : n x c\n",
    "    p = 1 - jnp.prod(1 - p_sites, 0)  # dimensions: c\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSORT_BASE = \"/Volumes/Scratch/Analysis\"\n",
    "ANALYSIS_BASE = \"/Volumes/Analysis\"\n",
    "dataset = \"2022-11-28-6\"\n",
    "wnoise = \"kilosort_data000/data000\"\n",
    "blanked_probs = 12\n",
    "\n",
    "estim_neg = \"data002\"\n",
    "\n",
    "outpath = os.path.join(GSORT_BASE, dataset, estim_neg, wnoise)\n",
    "electrical_path = os.path.join(ANALYSIS_BASE, dataset, estim_neg)\n",
    "parameters = loadmat(os.path.join(outpath, 'parameters.mat'))\n",
    "\n",
    "cells = parameters['cells'].flatten()\n",
    "num_cells = len(cells)\n",
    "num_patterns = max(parameters['patterns'].flatten())\n",
    "num_movies = parameters['movies'].flatten()[0]\n",
    "\n",
    "all_probs_neg = np.array(np.memmap(os.path.join(outpath, 'init_probs.dat'),mode='r',shape=(num_cells, num_patterns, num_movies), dtype='float32'))\n",
    "trials_neg = np.array(np.memmap(os.path.join(outpath, 'trial.dat'),mode='r',shape=(num_patterns, num_movies), dtype='int16'), dtype=int)\n",
    "amps_neg = np.tile(mutils.get_stim_amps_newlv(electrical_path, 1), (len(trials_neg), 1))\n",
    "\n",
    "all_probs_neg[:, :, :blanked_probs] = np.zeros(all_probs_neg[:, :, :blanked_probs].shape)\n",
    "\n",
    "for i in range(len(all_probs_neg)):\n",
    "    for j in range(len(all_probs_neg[i])):\n",
    "        all_probs_neg[i][j] = fitting.disambiguate_sigmoid(all_probs_neg[i][j], spont_limit=0.3, noise_limit=0.1)\n",
    "        \n",
    "all_probs_neg = all_probs_neg[:, :, ::-1]\n",
    "trials_neg = trials_neg[:, ::-1]\n",
    "amps_neg = amps_neg[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_pos = \"data003\"\n",
    "\n",
    "outpath = os.path.join(GSORT_BASE, dataset, estim_pos, wnoise)\n",
    "electrical_path = os.path.join(ANALYSIS_BASE, dataset, estim_pos)\n",
    "parameters = loadmat(os.path.join(outpath, 'parameters.mat'))\n",
    "\n",
    "cells = parameters['cells'].flatten()\n",
    "num_cells = len(cells)\n",
    "num_patterns = max(parameters['patterns'].flatten())\n",
    "num_movies = parameters['movies'].flatten()[0]\n",
    "\n",
    "all_probs_pos = np.array(np.memmap(os.path.join(outpath, 'init_probs.dat'),mode='r',shape=(num_cells, num_patterns, num_movies), dtype='float32'))\n",
    "trials_pos = np.array(np.memmap(os.path.join(outpath, 'trial.dat'),mode='r',shape=(num_patterns, num_movies), dtype='int16'), dtype=int)\n",
    "amps_pos = np.tile(mutils.get_stim_amps_newlv(electrical_path, 1), (len(trials_pos), 1))\n",
    "\n",
    "all_probs_pos[:, :, :blanked_probs] = np.zeros(all_probs_pos[:, :, :blanked_probs].shape)\n",
    "\n",
    "for i in range(len(all_probs_pos)):\n",
    "    for j in range(len(all_probs_pos[i])):\n",
    "        all_probs_pos[i][j] = fitting.disambiguate_sigmoid(all_probs_pos[i][j], spont_limit=0.3, noise_limit=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = np.concatenate((all_probs_neg, all_probs_pos), axis=2)\n",
    "trials = np.concatenate((trials_neg, trials_pos), axis=1)\n",
    "amps = np.concatenate((amps_neg, amps_pos), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_list(all_probs, amps, trials, w_inits_array):\n",
    "\n",
    "    input_list = []\n",
    "    for i in range(len(all_probs)):\n",
    "        for j in range(len(all_probs[i])):\n",
    "            probs = all_probs[i][j]\n",
    "            T = trials[j]\n",
    "            X = amps[j].reshape(-1, 1)\n",
    "\n",
    "            input_list += [(X, probs, T, w_inits_array[i][j])]\n",
    "\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = [1, 2]\n",
    "\n",
    "w_inits_array = np.zeros((all_probs.shape[0], all_probs.shape[1]), dtype=object)\n",
    "for i in range(len(w_inits_array)):\n",
    "    for j in range(len(w_inits_array[i])):\n",
    "        w_inits = []\n",
    "\n",
    "        for m in ms:\n",
    "            w_init = np.array(np.random.normal(size=(m, amps.reshape(-1, 1).shape[1]+1)))\n",
    "            w_inits.append(w_init)\n",
    "\n",
    "        w_inits_array[i][j] = w_inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = generate_input_list(all_probs, amps, trials, w_inits_array)\n",
    "\n",
    "pool = mp.Pool(processes=24)\n",
    "results = pool.starmap_async(fitting.fit_triplet_surface_new, input_list)\n",
    "mp_output = results.get()\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4016abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_output_array = np.array(mp_output, dtype=object)\n",
    "params_true = mp_output_array[:, 0].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "probs_true_tmp = mp_output_array[:, 1].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "inits = mp_output_array[:, 2].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "\n",
    "probs_true = np.zeros(all_probs.shape)\n",
    "for i in range(len(all_probs)):\n",
    "    for j in range(len(all_probs[i])):\n",
    "        probs_true[i][j] = probs_true_tmp[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a20d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATASET IF NEEDED\n",
    "\n",
    "for i in range(len(all_probs)):\n",
    "    for j in range(len(all_probs[i])):\n",
    "        if ~np.all(params_true[i][j][:, 0] == -np.inf):\n",
    "\n",
    "            print(params_true[i][j])\n",
    "            \n",
    "            plt.figure(0)\n",
    "            plt.xlim(-4.2, 4.2)\n",
    "            plt.ylim(-0.1, 1.1)\n",
    "            plt.scatter(amps[j], all_probs[i][j])\n",
    "            plt.plot(amps[j], probs_true[i][j])\n",
    "            plt.show()\n",
    "            input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef06638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spikes(p_true, t):\n",
    "    p_true, t = np.array(p_true), np.array(t).astype(int)\n",
    "    \n",
    "    p_empirical = []\n",
    "    for i in range(len(p_true)):\n",
    "        if t[i] == 0:\n",
    "            p_empirical += [0.5]\n",
    "        \n",
    "        else:\n",
    "            p_empirical += [np.mean(np.random.choice(np.array([0, 1]), \n",
    "                                                 p=np.array([1-p_true[i], p_true[i]]), \n",
    "                                                 size=t[i]))]\n",
    "        \n",
    "    p_empirical_array = np.array(p_empirical)\n",
    "\n",
    "    return p_empirical_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9cf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_spikes_array(true_probs, trials, NUM_THREADS=24):\n",
    "\n",
    "    input_list = []\n",
    "    for i in range(len(true_probs)):\n",
    "        for j in range(len(true_probs[i])):\n",
    "            input_list += [(true_probs[i][j], trials[j])]\n",
    "            \n",
    "    pool = mp.Pool(processes=NUM_THREADS)\n",
    "    results = pool.starmap_async(sample_spikes, input_list)\n",
    "    mp_output = results.get()\n",
    "    pool.close()\n",
    "\n",
    "    return np.array(mp_output).reshape(true_probs.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_array(true_params, curr_probs, true_probs):\n",
    "    \n",
    "    error = 0\n",
    "    cnt = 0\n",
    "    for i in range(len(true_params)):\n",
    "        for j in range(len(true_params[i])):\n",
    "            if ~np.all(true_params[i][j][:, 0] == -np.inf):\n",
    "                error += np.sqrt(np.sum((curr_probs[i][j] - true_probs[i][j])**2) / len(true_probs[i][j]))\n",
    "                cnt += 1\n",
    "\n",
    "    return error / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce58de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL CELLS IN DATASET\n",
    "\n",
    "total_cell_cnt = 0\n",
    "for i in range(len(params_true)):\n",
    "    for j in range(len(params_true[i])):\n",
    "        if ~np.all(params_true[i][j][:, 0] == -np.inf):\n",
    "            total_cell_cnt += 1\n",
    "print(total_cell_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4206097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def activation_probs_jac(x, w):\n",
    "#     prod = jnp.prod((1 / (1 + jnp.exp(jnp.dot(w, jnp.transpose(x))))), 0)\n",
    "#     sigmoid = 1 / (1 + jnp.exp(-jnp.dot(w, jnp.transpose(x))))\n",
    "#     # maybe clip something here?\n",
    "#     # sigmoid = jnp.clip(sigmoid, a_min=1e-5, a_max=1-1e-5)\n",
    "#     # prod = jnp.clip(prod, a_min=1e-5, a_max=1-1e-5)\n",
    "    \n",
    "#     jac_list = []\n",
    "#     for i in range(len(sigmoid)):\n",
    "#         jac_list.append(x * (sigmoid[i] * prod)[:, None])\n",
    "\n",
    "#     return jnp.hstack(jac_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85861c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def fisher_loss_array(probs_vec, transform_mat, jac_full, trials):\n",
    "    p_model = jnp.clip(probs_vec, a_min=1e-5, a_max=1-1e-5)\n",
    "    t = jnp.dot(transform_mat, trials).flatten()\n",
    "    I_p = t / (p_model * (1 - p_model))\n",
    "    I_w = jnp.dot((jac_full.T * I_p), jac_full) / len(p_model)\n",
    "\n",
    "    return jnp.sum(jnp.multiply(jac_full.T, jnp.dot(jnp.linalg.inv(I_w), jac_full.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_fisher_array(jac_full, probs_vec, transform_mat, T_prev, T, reg=0, step_size=1, n_steps=100, T_budget=5000):\n",
    "\n",
    "    optimizer = optax.adamw(step_size)\n",
    "    opt_state = optimizer.init(T)\n",
    "\n",
    "    @jax.jit\n",
    "    def update(jac_full, probs_vec, transform_mat, T_prev, T):\n",
    "        fisher_lambda = lambda T, jac_full, probs_vec, transform_mat, T_prev: fisher_loss_array(probs_vec, transform_mat, jac_full, T_prev + jnp.absolute(T)) + reg * jnp.absolute(jnp.sum(jnp.absolute(T)) - T_budget)\n",
    "        grads = jax.grad(fisher_lambda)(T, jac_full, probs_vec, transform_mat, T_prev)\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    losses = []\n",
    "    for step in range(n_steps):\n",
    "        print(step)\n",
    "        try:\n",
    "            grads = update(jac_full, probs_vec, transform_mat, T_prev, T)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state, params=T)\n",
    "            T = optax.apply_updates(T, updates)\n",
    "            \n",
    "            loss = fisher_loss_array(probs_vec, transform_mat, jac_full, T_prev + jnp.absolute(T))\n",
    "            loss_tuple = (loss, jnp.sum(jnp.absolute(T)), loss + reg * jnp.absolute(jnp.sum(jnp.absolute(T)) - T_budget),\n",
    "                          reg * jnp.absolute(jnp.sum(jnp.absolute(T)) - T_budget))\n",
    "            print(loss_tuple)\n",
    "            losses += [loss_tuple]\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "    return np.array(losses), T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_budget = 100000\n",
    "num_iters = 10\n",
    "budget = int(total_budget / num_iters)\n",
    "reg = 20\n",
    "T_step_size = 0.005\n",
    "T_n_steps = 5000\n",
    "init_trials = 5\n",
    "ms = [1, 2]\n",
    "\n",
    "T_prev = np.ones_like(trials, dtype=float) * init_trials\n",
    "T_prev_random = np.copy(T_prev)\n",
    "T_prev_uniform = np.copy(T_prev)\n",
    "probs_empirical = sample_spikes_array(probs_true, T_prev, NUM_THREADS=24)\n",
    "probs_empirical_random = np.copy(probs_empirical)\n",
    "probs_empirical_uniform = np.copy(probs_empirical)\n",
    "\n",
    "X = jnp.array(sm.add_constant(amps[0].reshape(-1, 1), has_constant='add'))\n",
    "w_inits_array = np.zeros((probs_empirical.shape[0], probs_empirical.shape[1]), dtype=object)\n",
    "for i in range(len(w_inits_array)):\n",
    "    for j in range(len(w_inits_array[i])):\n",
    "        w_inits = []\n",
    "\n",
    "        for m in ms:\n",
    "            w_init = np.array(np.random.normal(size=(m, amps.reshape(-1, 1).shape[1]+1)))\n",
    "            w_inits.append(w_init)\n",
    "\n",
    "        w_inits_array[i][j] = w_inits\n",
    "\n",
    "w_inits_array_random = np.copy(w_inits_array)\n",
    "w_inits_array_uniform = np.copy(w_inits_array)\n",
    "\n",
    "performances = []\n",
    "performances_random = []\n",
    "performances_uniform = []\n",
    "num_samples = []\n",
    "num_samples_uniform = []\n",
    "\n",
    "iter_cnt = 0\n",
    "while True:\n",
    "    input_list = generate_input_list(probs_empirical, amps, T_prev, w_inits_array)\n",
    "\n",
    "    pool = mp.Pool(processes=24)\n",
    "    results = pool.starmap_async(fitting.fit_triplet_surface_new, input_list)\n",
    "    mp_output = results.get()\n",
    "    pool.close()\n",
    "\n",
    "    mp_output_array = np.array(mp_output, dtype=object)\n",
    "    params_curr = mp_output_array[:, 0].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "    probs_curr_tmp = mp_output_array[:, 1].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "    w_inits_array = mp_output_array[:, 2].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "\n",
    "    probs_curr = np.zeros(all_probs.shape)\n",
    "    for i in range(len(all_probs)):\n",
    "        for j in range(len(all_probs[i])):\n",
    "            probs_curr[i][j] = probs_curr_tmp[i][j]\n",
    "\n",
    "    if iter_cnt == 0:\n",
    "        probs_curr_random = np.copy(probs_curr)     # this is only for iteration 0\n",
    "        probs_curr_uniform = np.copy(probs_curr)\n",
    "        \n",
    "        # random_draws = np.random.choice(len(T_prev.flatten()), size=budget)\n",
    "        # T_new_init = jnp.array(np.bincount(random_draws, minlength=len(T_prev.flatten())).astype(int).reshape(T_prev.shape), dtype=float)\n",
    "        T_new_init = jnp.ones_like(jnp.array(T_prev), dtype=float)\n",
    "        w_inits_array_random = np.copy(w_inits_array)\n",
    "        w_inits_array_uniform = np.copy(w_inits_array)\n",
    "\n",
    "    else:\n",
    "        T_new_init = jnp.absolute(t_final)\n",
    "        input_list_random = generate_input_list(probs_empirical_random, amps, T_prev_random, w_inits_array_random)\n",
    "\n",
    "        pool = mp.Pool(processes=24)\n",
    "        results_random = pool.starmap_async(fitting.fit_triplet_surface_new, input_list_random)\n",
    "        mp_output_random = results_random.get()\n",
    "        pool.close()\n",
    "\n",
    "        mp_output_array_random = np.array(mp_output_random, dtype=object)\n",
    "        params_curr_random = mp_output_array_random[:, 0].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "        probs_curr_tmp_random = mp_output_array_random[:, 1].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "        w_inits_array_random = mp_output_array_random[:, 2].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "\n",
    "        probs_curr_random = np.zeros(all_probs.shape)\n",
    "        for i in range(len(all_probs)):\n",
    "            for j in range(len(all_probs[i])):\n",
    "                probs_curr_random[i][j] = probs_curr_tmp_random[i][j]\n",
    "\n",
    "        input_list_uniform = generate_input_list(probs_empirical_uniform, amps, T_prev_uniform, w_inits_array_uniform)\n",
    "\n",
    "        pool = mp.Pool(processes=24)\n",
    "        results_uniform = pool.starmap_async(fitting.fit_triplet_surface_new, input_list_uniform)\n",
    "        mp_output_uniform = results_uniform.get()\n",
    "        pool.close()\n",
    "\n",
    "        mp_output_array_uniform = np.array(mp_output_uniform, dtype=object)\n",
    "        params_curr_uniform = mp_output_array_uniform[:, 0].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "        probs_curr_tmp_uniform = mp_output_array_uniform[:, 1].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "        w_inits_array_uniform = mp_output_array_uniform[:, 2].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "\n",
    "        probs_curr_uniform = np.zeros(all_probs.shape)\n",
    "        for i in range(len(all_probs)):\n",
    "            for j in range(len(all_probs[i])):\n",
    "                probs_curr_uniform[i][j] = probs_curr_tmp_uniform[i][j]\n",
    "\n",
    "    performance = get_performance_array(params_true, probs_curr, probs_true)\n",
    "    performance_random = get_performance_array(params_true, probs_curr_random, probs_true)\n",
    "    performance_uniform = get_performance_array(params_true, probs_curr_uniform, probs_true)\n",
    "\n",
    "    performances.append(performance)\n",
    "    performances_random.append(performance_random)\n",
    "    performances_uniform.append(performance_uniform)\n",
    "\n",
    "    print(performance, performance_random, performance_uniform)\n",
    "    \n",
    "    num_samples.append(np.sum(T_prev))\n",
    "    num_samples_uniform.append(np.sum(T_prev_uniform))\n",
    "    if iter_cnt >= num_iters:\n",
    "        break\n",
    "\n",
    "    jac_dict = collections.defaultdict(dict)\n",
    "    transform_mat = []\n",
    "    probs_vec = []\n",
    "    cell_cnt = 0\n",
    "    num_params = 0\n",
    "    for i in range(len(params_curr)):\n",
    "        for j in range(len(params_curr[i])):\n",
    "            if ~np.all(params_curr[i][j][:, 0] == -np.inf):\n",
    "                # jac_dict[i][j] = activation_probs_jac(X, jnp.array(params_curr[i][j]))\n",
    "                jac_dict[i][j] = jax.jacfwd(activation_probs, argnums=1)(X, jnp.array(params_curr[i][j])).reshape((len(X), params_curr[i][j].shape[0]*params_curr[i][j].shape[1]))  # c x l\n",
    "                num_params += jac_dict[i][j].shape[1]\n",
    "\n",
    "                transform = jnp.zeros(len(T_prev))\n",
    "                transform = transform.at[j].set(1)\n",
    "                transform_mat.append(transform)     # append a e-vector (512)\n",
    "\n",
    "                probs_vec.append(probs_curr[i][j])  # append a c-vector (80)\n",
    "                cell_cnt += 1\n",
    "\n",
    "    transform_mat = jnp.array(transform_mat)\n",
    "    probs_vec = jnp.hstack(probs_vec)\n",
    "\n",
    "    jac_full = jnp.zeros((len(probs_vec), num_params))\n",
    "    counter_axis0 = 0\n",
    "    counter_axis1 = 0\n",
    "    for i in jac_dict.keys():\n",
    "        for j in jac_dict[i].keys():\n",
    "            next_jac = jac_dict[i][j]\n",
    "\n",
    "            jac_full = jac_full.at[counter_axis0:counter_axis0+next_jac.shape[0], counter_axis1:counter_axis1+next_jac.shape[1]].set(next_jac)\n",
    "\n",
    "            counter_axis0 += next_jac.shape[0]\n",
    "            counter_axis1 += next_jac.shape[1]\n",
    "\n",
    "    print(f'Cells Found: {cell_cnt}/{total_cell_cnt}')\n",
    "    # break\n",
    "\n",
    "    print('Optimizing trials...')\n",
    "    losses, t_final = optimize_fisher_array(jac_full, probs_vec, transform_mat, jnp.array(T_prev), T_new_init, step_size=T_step_size,\n",
    "                                            n_steps=T_n_steps, reg=reg, T_budget=budget)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].plot(losses[:, 0])\n",
    "    axs[0].set_ylabel('Fisher Loss (A-optimality)')\n",
    "    axs[1].plot(losses[:, 1])\n",
    "    axs[1].set_ylabel('Total Trials')\n",
    "    axs[2].plot(losses[:, 2])\n",
    "    axs[2].set_ylabel('Regularized Loss, reg=' + str(reg))\n",
    "\n",
    "    fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "    plt.show()\n",
    "\n",
    "    T_new = jnp.round(jnp.absolute(t_final), 0)\n",
    "    print(jnp.sum(T_new))\n",
    "\n",
    "    if jnp.sum(T_new) < budget:\n",
    "        random_extra = np.random.choice(len(T_new.flatten()), size=int(budget - jnp.sum(T_new)),\n",
    "                                        p=np.array(jnp.absolute(t_final.flatten()))/np.sum(np.array(jnp.absolute(t_final.flatten()))))\n",
    "        T_new_extra = jnp.array(np.bincount(random_extra, minlength=len(T_new.flatten())).astype(int).reshape(T_new.shape))\n",
    "        T_new = T_new + T_new_extra\n",
    "\n",
    "    print(jnp.sum(T_new))\n",
    "\n",
    "    p_new = sample_spikes_array(probs_true, np.array(T_new), NUM_THREADS=24)\n",
    "    p_tmp = (p_new * np.array(T_new)[np.newaxis, :, :] + probs_empirical * T_prev[np.newaxis, :, :]) / ((np.array(T_new) + T_prev)[np.newaxis, :, :])\n",
    "    T_tmp = np.array(T_new) + T_prev\n",
    "\n",
    "    probs_empirical = p_tmp\n",
    "    T_prev = T_tmp\n",
    "\n",
    "    random_draws = np.random.choice(len(T_new.flatten()), size=int(jnp.sum(T_new)))\n",
    "    T_new_random = np.bincount(random_draws, minlength=len(T_new.flatten())).astype(int).reshape(T_new.shape)\n",
    "    p_new_random = sample_spikes_array(probs_true, T_new_random, NUM_THREADS=24)\n",
    "    \n",
    "    p_tmp_random = (p_new_random * T_new_random[np.newaxis, :, :] + probs_empirical_random * T_prev_random[np.newaxis, :, :]) / ((T_prev_random + T_new_random)[np.newaxis, :, :])\n",
    "    T_tmp_random = T_prev_random + T_new_random\n",
    "\n",
    "    probs_empirical_random = p_tmp_random\n",
    "    T_prev_random = T_tmp_random\n",
    "\n",
    "    T_new_uniform = np.ones_like(T_prev_uniform, dtype=float)\n",
    "    p_new_uniform = sample_spikes_array(probs_true, T_new_uniform, NUM_THREADS=24)\n",
    "\n",
    "    p_tmp_uniform = (p_new_uniform * T_new_uniform[np.newaxis, :, :] + probs_empirical_uniform * T_prev_uniform[np.newaxis, :, :]) / ((T_prev_uniform + T_new_uniform)[np.newaxis, :, :])\n",
    "    T_tmp_uniform = T_prev_uniform + T_new_uniform\n",
    "\n",
    "    probs_empirical_uniform = p_tmp_uniform\n",
    "    T_prev_uniform = T_tmp_uniform\n",
    "\n",
    "    iter_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c964ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "# plt.errorbar(np.mean(np.array(num_samples_stack), axis=0), np.mean(np.array(performance_stack), 0), \n",
    "#              yerr=np.std(np.array(performance_stack), axis=0), fmt='o', ls='-', linewidth=4, elinewidth=2, label='Active Learning', c='tab:blue', alpha=0.3)\n",
    "# plt.errorbar(np.mean(np.array(num_samples_stack), axis=0), np.mean(np.array(performance_stack_random), 0), \n",
    "#              yerr=np.std(np.array(performance_stack_random), axis=0), fmt='o', ls='-', linewidth=4, elinewidth=2, label='Random Baseline', c='tab:orange', alpha=0.3)\n",
    "\n",
    "plt.plot(np.array(num_samples)/trials.shape[0]/trials.shape[1], performances, linewidth=4, c='tab:blue', label='Active Learning')\n",
    "plt.plot(np.array(num_samples)/trials.shape[0]/trials.shape[1], performances_random, linewidth=4, c='tab:orange', label='Random Baseline')\n",
    "plt.plot(np.array(num_samples_uniform)/trials.shape[0]/trials.shape[1], performances_uniform, linewidth=4, c='tab:red', label='Uniform Sampling')\n",
    "\n",
    "plt.axhline(get_performance_array(params_true, probs_curr_baseline, probs_true), c='k', linestyle='--', linewidth=2, label='20 Uniform Trials')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel('Average Trials per Current Level', fontsize=24)\n",
    "plt.ylabel(r'RMSE', fontsize=24)\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "\n",
    "# plt.savefig('performances_5step_p2_n259_adamw.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_T = np.sum(T_prev, axis=1) - len(X) * init_trials\n",
    "vcd = vl.load_vision_data(os.path.join(ANALYSIS_BASE, dataset, wnoise), wnoise[-7:],\n",
    "                          include_neurons=True,\n",
    "                          include_ei=True,\n",
    "                          include_params=True,\n",
    "                          include_noise=True)\n",
    "\n",
    "coords = vcd.electrode_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c50a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "scat = ax.scatter(coords[:, 0], coords[:, 1], s=10, c=summed_T, vmin=0, vmax=500)\n",
    "clb = plt.colorbar(scat)\n",
    "clb.ax.set_ylabel(r'Number of Trials', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d577d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATASET IF NEEDED\n",
    "\n",
    "for i in range(len(probs_true)):\n",
    "    for j in range(len(probs_true[i])):\n",
    "        if ~np.all(params_true[i][j][:, 0] == -np.inf):\n",
    "\n",
    "            print(params_true[i][j])\n",
    "            print(params_curr[i][j])\n",
    "            \n",
    "            plt.figure(0)\n",
    "            plt.xlim(-4.4, 4.4)\n",
    "            plt.ylim(-0.1, 1.1)\n",
    "            plt.scatter(amps[j], probs_empirical[i][j])\n",
    "            plt.plot(amps[j], probs_curr[i][j])\n",
    "            plt.plot(amps[j], probs_true[i][j])\n",
    "            plt.show()\n",
    "            input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ce0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG FOUND: should be initializing with jnp.absolute(t_final) in other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c294f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_trials = 20\n",
    "T_baseline = np.ones_like(trials, dtype=float) * baseline_trials\n",
    "probs_baseline = sample_spikes_array(probs_true, T_baseline, NUM_THREADS=48)\n",
    "\n",
    "X = jnp.array(sm.add_constant(amps[0].reshape(-1, 1), has_constant='add'))\n",
    "w_inits_array_baseline = np.zeros((probs_baseline.shape[0], probs_baseline.shape[1]), dtype=object)\n",
    "for i in range(len(w_inits_array_baseline)):\n",
    "    for j in range(len(w_inits_array_baseline[i])):\n",
    "        w_inits = []\n",
    "\n",
    "        for m in ms:\n",
    "            w_init = np.array(np.random.normal(size=(m, amps.reshape(-1, 1).shape[1]+1)))\n",
    "            w_inits.append(w_init)\n",
    "\n",
    "        w_inits_array_baseline[i][j] = w_inits\n",
    "\n",
    "input_list_baseline = generate_input_list(probs_baseline, amps, T_baseline, w_inits_array_baseline)\n",
    "\n",
    "pool = mp.Pool(processes=24)\n",
    "results_baseline = pool.starmap_async(fitting.fit_triplet_surface_new, input_list_baseline)\n",
    "mp_output_baseline = results_baseline.get()\n",
    "pool.close()\n",
    "\n",
    "mp_output_array_baseline = np.array(mp_output_baseline, dtype=object)\n",
    "params_curr_baseline = mp_output_array_baseline[:, 0].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "probs_curr_baseline_tmp = mp_output_array_baseline[:, 1].reshape(all_probs.shape[0], all_probs.shape[1])\n",
    "\n",
    "probs_curr_baseline = np.zeros(all_probs.shape)\n",
    "for i in range(len(all_probs)):\n",
    "    for j in range(len(all_probs[i])):\n",
    "        probs_curr_baseline[i][j] = probs_curr_baseline_tmp[i][j]\n",
    "\n",
    "cell_cnt = 0\n",
    "for i in range(len(params_curr_baseline)):\n",
    "    for j in range(len(params_curr_baseline[i])):\n",
    "        if ~np.all(params_curr_baseline[i][j][:, 0] == -np.inf):\n",
    "            cell_cnt += 1\n",
    "                \n",
    "print(f'Cells Found: {cell_cnt}/{total_cell_cnt}')\n",
    "print(get_performance_array(params_true, probs_curr_baseline, probs_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATASET IF NEEDED\n",
    "\n",
    "for i in range(len(probs_true)):\n",
    "    for j in range(len(probs_true[i])):\n",
    "        good_inds = np.where((probs_true[i][j] >= 0.1) & (probs_true[i][j] <= 1 - 0.1))[0]\n",
    "        if len(good_inds) == 0:\n",
    "            continue\n",
    "\n",
    "        print(params_true[i][j])\n",
    "        \n",
    "        plt.figure(0)\n",
    "        plt.xlim(-4.4, 4.4)\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "        plt.scatter(amps[j], probs_baseline[i][j])\n",
    "        plt.plot(amps[j], probs_curr_baseline[i][j])\n",
    "        plt.plot(amps[j], probs_true[i][j])\n",
    "        plt.show()\n",
    "        input()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e9ddbef",
   "metadata": {},
   "source": [
    "# Old stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3593e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "total_budget = 10000\n",
    "num_iters = 5\n",
    "budget = int(total_budget / num_iters)\n",
    "reg = 20    #np.flip(np.logspace(-5, 3, 100000, base=2))\n",
    "num_restarts = 1\n",
    "T_step_size = 0.01 #0.01\n",
    "T_n_steps = 5000\n",
    "\n",
    "init_size = 200\n",
    "init_trials = 5\n",
    "\n",
    "performance_stack = []\n",
    "performance_stack_random = []\n",
    "num_samples_stack = []\n",
    "\n",
    "for restart in range(num_restarts):\n",
    "    print('Restart', restart + 1)\n",
    "    # Initialize amplitudes\n",
    "    init_inds = np.random.choice(len(X), replace=False, size=init_size)\n",
    "\n",
    "    # Initialize trials\n",
    "    T_prev = jnp.zeros(len(X_expt_orig))\n",
    "    T_prev = T_prev.at[init_inds].set(init_trials)\n",
    "    T_prev_random = jnp.copy(T_prev)\n",
    "\n",
    "    p_empirical = jnp.array(sample_spikes(p_true, T_prev))\n",
    "    p_empirical_random = jnp.copy(p_empirical)\n",
    "\n",
    "    performances = []\n",
    "    performances_random = []\n",
    "    num_samples = []\n",
    "\n",
    "    w_inits = []\n",
    "    for m in ms:\n",
    "        w_init = np.array(np.random.normal(size=(m, X.shape[1]+1)))\n",
    "        w_inits.append(w_init)\n",
    "\n",
    "    w_inits_random = copy(w_inits)\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    while True:\n",
    "        num_samples.append(np.sum(np.absolute(np.array(T_prev)).astype(int)))\n",
    "        sampled_inds = np.where(np.absolute(np.array(T_prev)).astype(int) > 0)[0]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig.clear()\n",
    "        ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "        fig.add_axes(ax)\n",
    "        plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "        plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "        plt.xlim(-1.8, 1.8)\n",
    "        plt.ylim(-1.8, 1.8)\n",
    "        ax.set_zlim(-1.8, 1.8)\n",
    "        ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "        scat = ax.scatter(X_expt_orig[sampled_inds, 0], \n",
    "                    X_expt_orig[sampled_inds, 1],\n",
    "                    X_expt_orig[sampled_inds, 2], marker='o', c=p_empirical[sampled_inds], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "        # scat = ax.scatter(X_expt_orig[sampled_inds, 0], \n",
    "        #             X_expt_orig[sampled_inds, 1],\n",
    "        #             X_expt_orig[sampled_inds, 2], marker='o', c=T_prev[sampled_inds], s=20, cmap=cm.jet, vmin=0, vmax=20)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        sampled_inds_random = np.where(np.absolute(np.array(T_prev_random)).astype(int) > 0)[0]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig.clear()\n",
    "        ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "        fig.add_axes(ax)\n",
    "        plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "        plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "        plt.xlim(-1.8, 1.8)\n",
    "        plt.ylim(-1.8, 1.8)\n",
    "        ax.set_zlim(-1.8, 1.8)\n",
    "        ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "        scat = ax.scatter(X_expt_orig[sampled_inds_random , 0], \n",
    "                    X_expt_orig[sampled_inds_random , 1],\n",
    "                    X_expt_orig[sampled_inds_random , 2], marker='o', c=p_empirical_random[sampled_inds_random], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "\n",
    "        # scat = ax.scatter(X_expt_orig[sampled_inds_random , 0], \n",
    "        #     X_expt_orig[sampled_inds_random , 1],\n",
    "        #     X_expt_orig[sampled_inds_random , 2], marker='o', c=T_prev_random[sampled_inds_random], s=20, cmap=cm.jet, vmin=0, vmax=20)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        good_inds = jnp.where((p_empirical[sampled_inds] > 0) & (p_empirical[sampled_inds] < 1))[0]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig.clear()\n",
    "        ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "        fig.add_axes(ax)\n",
    "        plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "        plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "        plt.xlim(-1.8, 1.8)\n",
    "        plt.ylim(-1.8, 1.8)\n",
    "        ax.set_zlim(-1.8, 1.8)\n",
    "        ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "        scat = ax.scatter(X_expt_orig[sampled_inds[good_inds], 0], \n",
    "                    X_expt_orig[sampled_inds[good_inds], 1],\n",
    "                    X_expt_orig[sampled_inds[good_inds], 2], marker='o', c=p_empirical[sampled_inds][good_inds], \n",
    "                    s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "        # scat = ax.scatter(X_expt_orig[sampled_inds, 0], \n",
    "        #             X_expt_orig[sampled_inds, 1],\n",
    "        #             X_expt_orig[sampled_inds, 2], marker='o', c=T_prev[sampled_inds], s=20, cmap=cm.jet, vmin=0, vmax=20)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        output = fitting.fit_triplet_surface_new(np.array(X[sampled_inds][good_inds]), \n",
    "                                              np.array(p_empirical[sampled_inds][good_inds]),\n",
    "                                              np.array(T_prev[sampled_inds][good_inds], dtype=int), w_inits,\n",
    "                                              method=method, jac=jac, reg_method='l2', \n",
    "                                              reg=l2_reg, R2_thresh=R2_thresh, verbose=True)\n",
    "        w_final = jnp.array(output[0])\n",
    "        w_inits = output[1]\n",
    "\n",
    "        print(w_final)\n",
    "\n",
    "        if cnt == 0:\n",
    "            T_new_init = jnp.zeros(len(T_prev)) + 1\n",
    "            w_final_random = jnp.copy(w_final)\n",
    "            w_inits_random = copy(w_inits)\n",
    "        else:\n",
    "            T_new_init = t_final\n",
    "            good_inds_random = jnp.where((p_empirical_random[sampled_inds_random] > 0) & (p_empirical_random[sampled_inds_random] < 1))[0]\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            fig.clear()\n",
    "            ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            fig.add_axes(ax)\n",
    "            plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "            plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "            plt.xlim(-1.8, 1.8)\n",
    "            plt.ylim(-1.8, 1.8)\n",
    "            ax.set_zlim(-1.8, 1.8)\n",
    "            ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "            scat = ax.scatter(X_expt_orig[sampled_inds_random[good_inds_random] , 0], \n",
    "                        X_expt_orig[sampled_inds_random[good_inds_random] , 1],\n",
    "                        X_expt_orig[sampled_inds_random[good_inds_random] , 2], marker='o', \n",
    "                        c=p_empirical_random[sampled_inds_random][good_inds_random], s=20, alpha=0.8, vmin=0, vmax=1)\n",
    "\n",
    "            # scat = ax.scatter(X_expt_orig[sampled_inds_random , 0], \n",
    "            #     X_expt_orig[sampled_inds_random , 1],\n",
    "            #     X_expt_orig[sampled_inds_random , 2], marker='o', c=T_prev_random[sampled_inds_random], s=20, cmap=cm.jet, vmin=0, vmax=20)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            output = fitting.fit_triplet_surface_new(np.array(X[sampled_inds_random][good_inds_random]), \n",
    "                                              np.array(p_empirical_random[sampled_inds_random][good_inds_random]),\n",
    "                                              np.array(T_prev_random[sampled_inds_random][good_inds_random], dtype=int),\n",
    "                                              w_inits_random, method=method, jac=jac, reg_method='l2', \n",
    "                                              reg=l2_reg, R2_thresh=R2_thresh, verbose=True)\n",
    "            w_final_random = jnp.array(output[0])\n",
    "            w_inits_random = output[1]\n",
    "\n",
    "        print(w_final_random)\n",
    "\n",
    "        performance = get_performance_AL(jnp.array(sm.add_constant(X, has_constant='add')), w_final, p_true)\n",
    "        performances.append(performance)\n",
    "        \n",
    "        performance_random = get_performance_AL(jnp.array(sm.add_constant(X, has_constant='add')), w_final_random, p_true)\n",
    "        performances_random.append(performance_random)\n",
    "\n",
    "        print(performance, performance_random)\n",
    "        # print('\\n')\n",
    "\n",
    "        if cnt >= num_iters:\n",
    "            break\n",
    "        \n",
    "        losses, t_final = optimize_fisher(jnp.array(sm.add_constant(X, has_constant='add')), w_final, T_prev, T_new_init, reg=reg, step_size=T_step_size, n_steps=T_n_steps, T_budget=budget)\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].plot(losses[:, 0])\n",
    "        axs[0].set_ylabel('Fisher Loss (A-optimality)')\n",
    "        axs[1].plot(losses[:, 1])\n",
    "        axs[1].set_ylabel('Total Trials')\n",
    "        axs[2].plot(losses[:, 2])\n",
    "        axs[2].set_ylabel('Regularized Loss, reg=' + str(reg))\n",
    "\n",
    "        fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "        plt.show()\n",
    "\n",
    "        T_new = jnp.round(jnp.absolute(t_final), 0)#(t_final + T_new_explore), 0)\n",
    "        print(jnp.sum(T_new))\n",
    "        plt.figure()\n",
    "        plt.plot(T_new)\n",
    "        plt.show()\n",
    "\n",
    "        if jnp.sum(T_new) < budget:\n",
    "            random_extra = np.random.choice(len(X), size=int(budget - jnp.sum(T_new)), \n",
    "                                            p=np.array(jnp.absolute(t_final))/np.sum(np.array(jnp.absolute(t_final))))\n",
    "            T_new_extra = jnp.array(np.bincount(random_extra, minlength=len(X))).astype(int)\n",
    "            T_new = T_new + T_new_extra\n",
    "            \n",
    "            print(jnp.sum(T_new))\n",
    "            plt.figure()\n",
    "            plt.plot(T_new)\n",
    "            plt.show()\n",
    "\n",
    "        p_new = jnp.array(sample_spikes(p_true, T_new))\n",
    "\n",
    "        p_tmp = (p_new * T_new + p_empirical * T_prev) / (T_prev + T_new)\n",
    "        T_tmp = T_prev + T_new\n",
    "        p_tmp = p_tmp.at[jnp.isnan(p_tmp)].set(0.5)\n",
    "\n",
    "        p_empirical = p_tmp\n",
    "        T_prev = T_tmp\n",
    "\n",
    "        # print(jnp.sum(T_tmp))\n",
    "\n",
    "        random_draws = np.random.choice(len(X), size=int(jnp.sum(T_new)))\n",
    "        T_new_random = jnp.array(np.bincount(random_draws, minlength=len(X))).astype(int)\n",
    "        p_new_random = jnp.array(sample_spikes(p_true, T_new_random))\n",
    "        \n",
    "        p_tmp_random = (p_new_random * T_new_random + p_empirical_random * T_prev_random) / (T_prev_random + T_new_random)\n",
    "        T_tmp_random = T_prev_random + T_new_random\n",
    "        p_tmp_random = p_tmp_random.at[jnp.isnan(p_tmp_random)].set(0.5)\n",
    "\n",
    "        p_empirical_random = p_tmp_random\n",
    "        T_prev_random = T_tmp_random\n",
    "\n",
    "        cnt += 1\n",
    "        \n",
    "\n",
    "        # input()\n",
    "    \n",
    "    performance_stack.append(performances)\n",
    "    performance_stack_random.append(performances_random)\n",
    "    num_samples_stack.append(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('sampling_map_p3_n296.mat', {'X': np.array(X_expt_orig),\n",
    "                                     'p_empirical': np.array(p_empirical),\n",
    "                                     'sampled_inds': np.array(sampled_inds), \n",
    "                                     'T': np.array(T_prev),\n",
    "                                     'init_inds': init_inds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.clear()\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "ax.view_init(elev=16., azim=-50)\n",
    "fig.add_axes(ax)\n",
    "plt.xlabel(r'$I_1$ ($\\mu$A)', fontsize=16)\n",
    "plt.ylabel(r'$I_2$ ($\\mu$A)', fontsize=16)\n",
    "plt.xlim(-1.8, 1.8)\n",
    "plt.ylim(-1.8, 1.8)\n",
    "ax.set_zlim(-1.8, 1.8)\n",
    "ax.set_zlabel(r'$I_3$ ($\\mu$A)', fontsize=16)\n",
    "\n",
    "T_prev_tmp = T_prev.at[init_inds].set(T_prev[init_inds]-init_trials)\n",
    "sampled_inds_tmp = np.where(np.absolute(np.array(T_prev_tmp)).astype(int) > 0)[0]\n",
    "scat = ax.scatter(X_expt_orig[sampled_inds_tmp, 0], \n",
    "            X_expt_orig[sampled_inds_tmp, 1],\n",
    "            X_expt_orig[sampled_inds_tmp, 2], marker='o', c=T_prev_tmp[sampled_inds_tmp], s=20, cmap=cm.jet, vmin=0, vmax=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savemat('performances_5step_p2_n259_adamw.mat', {'performance_stack': np.array(performance_stack),\n",
    "#                                                 'performance_stack_random': np.array(performance_stack_random)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61de6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.errorbar(np.mean(np.array(num_samples_stack), axis=0), np.mean(np.array(performance_stack), 0), \n",
    "             yerr=np.std(np.array(performance_stack), axis=0), fmt='o', ls='-', linewidth=4, elinewidth=2, label='Active Learning', c='tab:blue', alpha=0.3)\n",
    "plt.errorbar(np.mean(np.array(num_samples_stack), axis=0), np.mean(np.array(performance_stack_random), 0), \n",
    "             yerr=np.std(np.array(performance_stack_random), axis=0), fmt='o', ls='-', linewidth=4, elinewidth=2, label='Random Baseline', c='tab:orange', alpha=0.3)\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel('Number of Trials Sampled', fontsize=24)\n",
    "plt.ylabel(r'RMSE', fontsize=24)\n",
    "plt.legend(fontsize=20)\n",
    "# plt.ylim(0.36, 0.4)\n",
    "\n",
    "# plt.savefig('performances_5step_p2_n259_adamw.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5208611",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_true_t, w_true_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos = fitting.all_combos(np.arange(len(cells)))\n",
    "ws_full = []\n",
    "for i in range(len(cells)):\n",
    "    ws_full.append(np.array(ws[i]))\n",
    "\n",
    "ws_active = []\n",
    "ws_active += [np.array(w_final_t)]\n",
    "ws_active += [np.array(w_final_nt)]\n",
    "\n",
    "for j in all_combos:\n",
    "    combo = np.array(j)\n",
    "    if len(combo) != 0 and len(combo) != len(cells):\n",
    "        targets = combo\n",
    "        selectivities_full.append(fitting.selectivity_triplet(ws_full, targets))\n",
    "        selectivities_active.append(fitting.selectivity_triplet(ws_active, targets))\n",
    "        datasets.append((dataset, wnoise, estim, p, cells, cells[targets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afa60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectivities_full, selectivities_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73133528",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7fbb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(selectivities_full)[:, 1]\n",
    "y = np.vstack((np.array(selectivities_full)[:, 0], np.array(selectivities_active)[:, 0])).T\n",
    "\n",
    "lines = []\n",
    "for i, j in zip(x, y):\n",
    "    pair = [(i, j[0]), (i, j[1])]\n",
    "    lines.append(pair)\n",
    "\n",
    "linecoll = matcoll.LineCollection(lines, colors='k')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, [i for (i,j) in y], 's', c='tab:blue', markersize = 10, alpha=0.8, label='Full Dataset')\n",
    "ax.plot(x, [j for (i,j) in y], 'o', c='tab:red', markersize = 10, alpha=0.8, label='Subsampled Dataset')\n",
    "ax.add_collection(linecoll)\n",
    "ax.plot(np.linspace(-0.01, 1.01, 100), np.linspace(-0.01, 1.01, 100), linestyle='--', c='k')\n",
    "ax.set_xlabel('Single-Electrode Selectivity', fontsize=22)\n",
    "ax.set_ylabel('Triplet Selectivity', fontsize=22)\n",
    "ax.tick_params('both', labelsize=18)\n",
    "ax.legend(fontsize=16)\n",
    "fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "plt.savefig('fig2_NER.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1804235",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('selectivities_full.npy', np.array(selectivities_full))\n",
    "np.save('selectivities_active.npy', np.array(selectivities_active))\n",
    "np.save('datasets.npy', np.array(datasets, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a9bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvasi39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a49c36f17b22be80bca1a531e420dccca9dd908a69799277bc977a4a0d3e51d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
